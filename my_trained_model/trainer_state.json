{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 20841,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0023991171248980373,
      "grad_norm": 3.084608316421509,
      "learning_rate": 1.9952977304352e-05,
      "loss": 1.5678,
      "step": 50
    },
    {
      "epoch": 0.004798234249796075,
      "grad_norm": 3.5279314517974854,
      "learning_rate": 1.9904994961854037e-05,
      "loss": 1.2268,
      "step": 100
    },
    {
      "epoch": 0.007197351374694113,
      "grad_norm": 6.657206058502197,
      "learning_rate": 1.9857012619356077e-05,
      "loss": 0.9368,
      "step": 150
    },
    {
      "epoch": 0.00959646849959215,
      "grad_norm": 7.874202251434326,
      "learning_rate": 1.9809030276858118e-05,
      "loss": 0.7497,
      "step": 200
    },
    {
      "epoch": 0.011995585624490188,
      "grad_norm": 8.544848442077637,
      "learning_rate": 1.9761047934360158e-05,
      "loss": 0.5741,
      "step": 250
    },
    {
      "epoch": 0.014394702749388226,
      "grad_norm": 7.999168395996094,
      "learning_rate": 1.97130655918622e-05,
      "loss": 0.5346,
      "step": 300
    },
    {
      "epoch": 0.016793819874286263,
      "grad_norm": 12.603209495544434,
      "learning_rate": 1.9665083249364236e-05,
      "loss": 0.4131,
      "step": 350
    },
    {
      "epoch": 0.0191929369991843,
      "grad_norm": 13.774415969848633,
      "learning_rate": 1.9617100906866276e-05,
      "loss": 0.4249,
      "step": 400
    },
    {
      "epoch": 0.021592054124082338,
      "grad_norm": 17.769855499267578,
      "learning_rate": 1.9569118564368313e-05,
      "loss": 0.3253,
      "step": 450
    },
    {
      "epoch": 0.023991171248980377,
      "grad_norm": 11.167913436889648,
      "learning_rate": 1.9521136221870354e-05,
      "loss": 0.3173,
      "step": 500
    },
    {
      "epoch": 0.026390288373878412,
      "grad_norm": 2.4434731006622314,
      "learning_rate": 1.9473153879372394e-05,
      "loss": 0.3027,
      "step": 550
    },
    {
      "epoch": 0.02878940549877645,
      "grad_norm": 13.840670585632324,
      "learning_rate": 1.942517153687443e-05,
      "loss": 0.3125,
      "step": 600
    },
    {
      "epoch": 0.031188522623674487,
      "grad_norm": 2.4622180461883545,
      "learning_rate": 1.937718919437647e-05,
      "loss": 0.259,
      "step": 650
    },
    {
      "epoch": 0.033587639748572526,
      "grad_norm": 7.458559513092041,
      "learning_rate": 1.9329206851878512e-05,
      "loss": 0.2217,
      "step": 700
    },
    {
      "epoch": 0.03598675687347056,
      "grad_norm": 19.749879837036133,
      "learning_rate": 1.928122450938055e-05,
      "loss": 0.2807,
      "step": 750
    },
    {
      "epoch": 0.0383858739983686,
      "grad_norm": 0.40241292119026184,
      "learning_rate": 1.923324216688259e-05,
      "loss": 0.2321,
      "step": 800
    },
    {
      "epoch": 0.04078499112326664,
      "grad_norm": 11.69312572479248,
      "learning_rate": 1.9185259824384627e-05,
      "loss": 0.2152,
      "step": 850
    },
    {
      "epoch": 0.043184108248164675,
      "grad_norm": 0.30043482780456543,
      "learning_rate": 1.9137277481886667e-05,
      "loss": 0.2204,
      "step": 900
    },
    {
      "epoch": 0.04558322537306271,
      "grad_norm": 5.186201095581055,
      "learning_rate": 1.9089295139388707e-05,
      "loss": 0.233,
      "step": 950
    },
    {
      "epoch": 0.04798234249796075,
      "grad_norm": 3.0212318897247314,
      "learning_rate": 1.9041312796890744e-05,
      "loss": 0.261,
      "step": 1000
    },
    {
      "epoch": 0.05038145962285879,
      "grad_norm": 4.051560401916504,
      "learning_rate": 1.8993330454392785e-05,
      "loss": 0.2281,
      "step": 1050
    },
    {
      "epoch": 0.052780576747756824,
      "grad_norm": 0.33993008732795715,
      "learning_rate": 1.8945348111894822e-05,
      "loss": 0.2013,
      "step": 1100
    },
    {
      "epoch": 0.05517969387265486,
      "grad_norm": 0.1334814429283142,
      "learning_rate": 1.8897365769396862e-05,
      "loss": 0.2008,
      "step": 1150
    },
    {
      "epoch": 0.0575788109975529,
      "grad_norm": 3.748403787612915,
      "learning_rate": 1.8849383426898903e-05,
      "loss": 0.2345,
      "step": 1200
    },
    {
      "epoch": 0.05997792812245094,
      "grad_norm": 9.968474388122559,
      "learning_rate": 1.880140108440094e-05,
      "loss": 0.2308,
      "step": 1250
    },
    {
      "epoch": 0.062377045247348974,
      "grad_norm": 16.356056213378906,
      "learning_rate": 1.8753418741902984e-05,
      "loss": 0.1879,
      "step": 1300
    },
    {
      "epoch": 0.06477616237224701,
      "grad_norm": 3.276383399963379,
      "learning_rate": 1.870543639940502e-05,
      "loss": 0.2428,
      "step": 1350
    },
    {
      "epoch": 0.06717527949714505,
      "grad_norm": 8.735217094421387,
      "learning_rate": 1.865745405690706e-05,
      "loss": 0.1789,
      "step": 1400
    },
    {
      "epoch": 0.0695743966220431,
      "grad_norm": 0.742955207824707,
      "learning_rate": 1.8609471714409098e-05,
      "loss": 0.1872,
      "step": 1450
    },
    {
      "epoch": 0.07197351374694112,
      "grad_norm": 5.696282863616943,
      "learning_rate": 1.856148937191114e-05,
      "loss": 0.1536,
      "step": 1500
    },
    {
      "epoch": 0.07437263087183917,
      "grad_norm": 12.409571647644043,
      "learning_rate": 1.851350702941318e-05,
      "loss": 0.1718,
      "step": 1550
    },
    {
      "epoch": 0.0767717479967372,
      "grad_norm": 20.156679153442383,
      "learning_rate": 1.8465524686915216e-05,
      "loss": 0.1855,
      "step": 1600
    },
    {
      "epoch": 0.07917086512163524,
      "grad_norm": 1.6301581859588623,
      "learning_rate": 1.8417542344417257e-05,
      "loss": 0.196,
      "step": 1650
    },
    {
      "epoch": 0.08156998224653328,
      "grad_norm": 30.51593780517578,
      "learning_rate": 1.8369560001919297e-05,
      "loss": 0.1922,
      "step": 1700
    },
    {
      "epoch": 0.08396909937143131,
      "grad_norm": 3.26008939743042,
      "learning_rate": 1.8321577659421334e-05,
      "loss": 0.18,
      "step": 1750
    },
    {
      "epoch": 0.08636821649632935,
      "grad_norm": 4.0521345138549805,
      "learning_rate": 1.8273595316923375e-05,
      "loss": 0.1695,
      "step": 1800
    },
    {
      "epoch": 0.08876733362122739,
      "grad_norm": 2.33125638961792,
      "learning_rate": 1.822561297442541e-05,
      "loss": 0.1743,
      "step": 1850
    },
    {
      "epoch": 0.09116645074612542,
      "grad_norm": 35.66667556762695,
      "learning_rate": 1.8177630631927452e-05,
      "loss": 0.1698,
      "step": 1900
    },
    {
      "epoch": 0.09356556787102346,
      "grad_norm": 9.989716529846191,
      "learning_rate": 1.8129648289429492e-05,
      "loss": 0.2033,
      "step": 1950
    },
    {
      "epoch": 0.0959646849959215,
      "grad_norm": 0.8506258726119995,
      "learning_rate": 1.808166594693153e-05,
      "loss": 0.1849,
      "step": 2000
    },
    {
      "epoch": 0.09836380212081954,
      "grad_norm": 5.092310428619385,
      "learning_rate": 1.803368360443357e-05,
      "loss": 0.1722,
      "step": 2050
    },
    {
      "epoch": 0.10076291924571758,
      "grad_norm": 9.569878578186035,
      "learning_rate": 1.7985701261935607e-05,
      "loss": 0.1801,
      "step": 2100
    },
    {
      "epoch": 0.10316203637061562,
      "grad_norm": 4.8560471534729,
      "learning_rate": 1.7937718919437647e-05,
      "loss": 0.1729,
      "step": 2150
    },
    {
      "epoch": 0.10556115349551365,
      "grad_norm": 7.071294784545898,
      "learning_rate": 1.7889736576939688e-05,
      "loss": 0.1709,
      "step": 2200
    },
    {
      "epoch": 0.10796027062041169,
      "grad_norm": 1.498997449874878,
      "learning_rate": 1.7841754234441725e-05,
      "loss": 0.1356,
      "step": 2250
    },
    {
      "epoch": 0.11035938774530972,
      "grad_norm": 2.437080144882202,
      "learning_rate": 1.7793771891943765e-05,
      "loss": 0.1393,
      "step": 2300
    },
    {
      "epoch": 0.11275850487020776,
      "grad_norm": 8.08880615234375,
      "learning_rate": 1.7745789549445806e-05,
      "loss": 0.1831,
      "step": 2350
    },
    {
      "epoch": 0.1151576219951058,
      "grad_norm": 6.703314304351807,
      "learning_rate": 1.7697807206947846e-05,
      "loss": 0.1475,
      "step": 2400
    },
    {
      "epoch": 0.11755673912000383,
      "grad_norm": 1.9065935611724854,
      "learning_rate": 1.7649824864449883e-05,
      "loss": 0.1326,
      "step": 2450
    },
    {
      "epoch": 0.11995585624490188,
      "grad_norm": 0.13769207894802094,
      "learning_rate": 1.7601842521951924e-05,
      "loss": 0.1562,
      "step": 2500
    },
    {
      "epoch": 0.12235497336979992,
      "grad_norm": 1.4173076152801514,
      "learning_rate": 1.7553860179453964e-05,
      "loss": 0.1686,
      "step": 2550
    },
    {
      "epoch": 0.12475409049469795,
      "grad_norm": 15.828062057495117,
      "learning_rate": 1.7505877836956e-05,
      "loss": 0.115,
      "step": 2600
    },
    {
      "epoch": 0.12715320761959598,
      "grad_norm": 1.1865681409835815,
      "learning_rate": 1.745789549445804e-05,
      "loss": 0.1413,
      "step": 2650
    },
    {
      "epoch": 0.12955232474449402,
      "grad_norm": 27.045997619628906,
      "learning_rate": 1.7409913151960082e-05,
      "loss": 0.1234,
      "step": 2700
    },
    {
      "epoch": 0.13195144186939206,
      "grad_norm": 2.264005661010742,
      "learning_rate": 1.736193080946212e-05,
      "loss": 0.1207,
      "step": 2750
    },
    {
      "epoch": 0.1343505589942901,
      "grad_norm": 3.4871065616607666,
      "learning_rate": 1.731394846696416e-05,
      "loss": 0.1419,
      "step": 2800
    },
    {
      "epoch": 0.13674967611918815,
      "grad_norm": 1.944515585899353,
      "learning_rate": 1.7265966124466197e-05,
      "loss": 0.1895,
      "step": 2850
    },
    {
      "epoch": 0.1391487932440862,
      "grad_norm": 0.7259395122528076,
      "learning_rate": 1.7217983781968237e-05,
      "loss": 0.1442,
      "step": 2900
    },
    {
      "epoch": 0.1415479103689842,
      "grad_norm": 1.3091034889221191,
      "learning_rate": 1.7170001439470278e-05,
      "loss": 0.1038,
      "step": 2950
    },
    {
      "epoch": 0.14394702749388225,
      "grad_norm": 3.5263783931732178,
      "learning_rate": 1.7122019096972315e-05,
      "loss": 0.1549,
      "step": 3000
    },
    {
      "epoch": 0.1463461446187803,
      "grad_norm": 2.200131416320801,
      "learning_rate": 1.7074036754474355e-05,
      "loss": 0.1513,
      "step": 3050
    },
    {
      "epoch": 0.14874526174367833,
      "grad_norm": 4.21799898147583,
      "learning_rate": 1.7026054411976392e-05,
      "loss": 0.1469,
      "step": 3100
    },
    {
      "epoch": 0.15114437886857637,
      "grad_norm": 3.613861322402954,
      "learning_rate": 1.6978072069478433e-05,
      "loss": 0.1269,
      "step": 3150
    },
    {
      "epoch": 0.1535434959934744,
      "grad_norm": 7.134551048278809,
      "learning_rate": 1.6930089726980473e-05,
      "loss": 0.2212,
      "step": 3200
    },
    {
      "epoch": 0.15594261311837243,
      "grad_norm": 5.587521076202393,
      "learning_rate": 1.688210738448251e-05,
      "loss": 0.1284,
      "step": 3250
    },
    {
      "epoch": 0.15834173024327047,
      "grad_norm": 1.3570812940597534,
      "learning_rate": 1.683412504198455e-05,
      "loss": 0.166,
      "step": 3300
    },
    {
      "epoch": 0.16074084736816852,
      "grad_norm": 0.7649062275886536,
      "learning_rate": 1.678614269948659e-05,
      "loss": 0.1316,
      "step": 3350
    },
    {
      "epoch": 0.16313996449306656,
      "grad_norm": 4.068013668060303,
      "learning_rate": 1.6738160356988628e-05,
      "loss": 0.1227,
      "step": 3400
    },
    {
      "epoch": 0.1655390816179646,
      "grad_norm": 1.202775001525879,
      "learning_rate": 1.669017801449067e-05,
      "loss": 0.1699,
      "step": 3450
    },
    {
      "epoch": 0.16793819874286262,
      "grad_norm": 0.9773761630058289,
      "learning_rate": 1.664219567199271e-05,
      "loss": 0.0983,
      "step": 3500
    },
    {
      "epoch": 0.17033731586776066,
      "grad_norm": 0.10767271369695663,
      "learning_rate": 1.659421332949475e-05,
      "loss": 0.1511,
      "step": 3550
    },
    {
      "epoch": 0.1727364329926587,
      "grad_norm": 2.7799363136291504,
      "learning_rate": 1.6546230986996786e-05,
      "loss": 0.1361,
      "step": 3600
    },
    {
      "epoch": 0.17513555011755674,
      "grad_norm": 1.7543660402297974,
      "learning_rate": 1.6498248644498827e-05,
      "loss": 0.1061,
      "step": 3650
    },
    {
      "epoch": 0.17753466724245479,
      "grad_norm": 2.020426034927368,
      "learning_rate": 1.6450266302000867e-05,
      "loss": 0.1322,
      "step": 3700
    },
    {
      "epoch": 0.1799337843673528,
      "grad_norm": 2.541175603866577,
      "learning_rate": 1.6402283959502904e-05,
      "loss": 0.1297,
      "step": 3750
    },
    {
      "epoch": 0.18233290149225084,
      "grad_norm": 3.852933883666992,
      "learning_rate": 1.6354301617004945e-05,
      "loss": 0.1429,
      "step": 3800
    },
    {
      "epoch": 0.18473201861714889,
      "grad_norm": 3.36795711517334,
      "learning_rate": 1.6306319274506982e-05,
      "loss": 0.1668,
      "step": 3850
    },
    {
      "epoch": 0.18713113574204693,
      "grad_norm": 2.8048155307769775,
      "learning_rate": 1.6258336932009022e-05,
      "loss": 0.1236,
      "step": 3900
    },
    {
      "epoch": 0.18953025286694497,
      "grad_norm": 1.2536282539367676,
      "learning_rate": 1.6210354589511063e-05,
      "loss": 0.1153,
      "step": 3950
    },
    {
      "epoch": 0.191929369991843,
      "grad_norm": 0.7015740275382996,
      "learning_rate": 1.61623722470131e-05,
      "loss": 0.0974,
      "step": 4000
    },
    {
      "epoch": 0.19432848711674103,
      "grad_norm": 2.6252970695495605,
      "learning_rate": 1.611438990451514e-05,
      "loss": 0.1292,
      "step": 4050
    },
    {
      "epoch": 0.19672760424163907,
      "grad_norm": 1.109119176864624,
      "learning_rate": 1.606640756201718e-05,
      "loss": 0.1456,
      "step": 4100
    },
    {
      "epoch": 0.1991267213665371,
      "grad_norm": 1.8660235404968262,
      "learning_rate": 1.6018425219519218e-05,
      "loss": 0.1216,
      "step": 4150
    },
    {
      "epoch": 0.20152583849143516,
      "grad_norm": 0.9752749800682068,
      "learning_rate": 1.5970442877021258e-05,
      "loss": 0.1437,
      "step": 4200
    },
    {
      "epoch": 0.2039249556163332,
      "grad_norm": 2.2492592334747314,
      "learning_rate": 1.5922460534523295e-05,
      "loss": 0.119,
      "step": 4250
    },
    {
      "epoch": 0.20632407274123124,
      "grad_norm": 1.5396242141723633,
      "learning_rate": 1.5874478192025335e-05,
      "loss": 0.1411,
      "step": 4300
    },
    {
      "epoch": 0.20872318986612926,
      "grad_norm": 7.70644998550415,
      "learning_rate": 1.5826495849527376e-05,
      "loss": 0.1314,
      "step": 4350
    },
    {
      "epoch": 0.2111223069910273,
      "grad_norm": 0.3936925530433655,
      "learning_rate": 1.5778513507029413e-05,
      "loss": 0.0863,
      "step": 4400
    },
    {
      "epoch": 0.21352142411592534,
      "grad_norm": 16.55129051208496,
      "learning_rate": 1.5730531164531453e-05,
      "loss": 0.1147,
      "step": 4450
    },
    {
      "epoch": 0.21592054124082338,
      "grad_norm": 1.4599473476409912,
      "learning_rate": 1.568254882203349e-05,
      "loss": 0.1001,
      "step": 4500
    },
    {
      "epoch": 0.21831965836572143,
      "grad_norm": 1.4535579681396484,
      "learning_rate": 1.563456647953553e-05,
      "loss": 0.1275,
      "step": 4550
    },
    {
      "epoch": 0.22071877549061944,
      "grad_norm": 1.6108684539794922,
      "learning_rate": 1.558658413703757e-05,
      "loss": 0.1179,
      "step": 4600
    },
    {
      "epoch": 0.22311789261551748,
      "grad_norm": 1.0240535736083984,
      "learning_rate": 1.5538601794539612e-05,
      "loss": 0.1314,
      "step": 4650
    },
    {
      "epoch": 0.22551700974041552,
      "grad_norm": 0.024366676807403564,
      "learning_rate": 1.5490619452041652e-05,
      "loss": 0.1352,
      "step": 4700
    },
    {
      "epoch": 0.22791612686531357,
      "grad_norm": 1.5886825323104858,
      "learning_rate": 1.544263710954369e-05,
      "loss": 0.1167,
      "step": 4750
    },
    {
      "epoch": 0.2303152439902116,
      "grad_norm": 1.1021270751953125,
      "learning_rate": 1.539465476704573e-05,
      "loss": 0.1437,
      "step": 4800
    },
    {
      "epoch": 0.23271436111510965,
      "grad_norm": 0.6993779540061951,
      "learning_rate": 1.5346672424547767e-05,
      "loss": 0.0921,
      "step": 4850
    },
    {
      "epoch": 0.23511347824000767,
      "grad_norm": 7.236451625823975,
      "learning_rate": 1.5298690082049807e-05,
      "loss": 0.0801,
      "step": 4900
    },
    {
      "epoch": 0.2375125953649057,
      "grad_norm": 18.836395263671875,
      "learning_rate": 1.5250707739551846e-05,
      "loss": 0.1024,
      "step": 4950
    },
    {
      "epoch": 0.23991171248980375,
      "grad_norm": 1.794745922088623,
      "learning_rate": 1.5202725397053886e-05,
      "loss": 0.1084,
      "step": 5000
    },
    {
      "epoch": 0.2423108296147018,
      "grad_norm": 1.6079127788543701,
      "learning_rate": 1.5154743054555925e-05,
      "loss": 0.0929,
      "step": 5050
    },
    {
      "epoch": 0.24470994673959984,
      "grad_norm": 25.786178588867188,
      "learning_rate": 1.5106760712057964e-05,
      "loss": 0.1414,
      "step": 5100
    },
    {
      "epoch": 0.24710906386449785,
      "grad_norm": 3.2427070140838623,
      "learning_rate": 1.5058778369560003e-05,
      "loss": 0.1253,
      "step": 5150
    },
    {
      "epoch": 0.2495081809893959,
      "grad_norm": 5.624967575073242,
      "learning_rate": 1.5010796027062043e-05,
      "loss": 0.1346,
      "step": 5200
    },
    {
      "epoch": 0.25190729811429396,
      "grad_norm": 2.6232964992523193,
      "learning_rate": 1.4962813684564082e-05,
      "loss": 0.1429,
      "step": 5250
    },
    {
      "epoch": 0.25430641523919195,
      "grad_norm": 4.3463239669799805,
      "learning_rate": 1.491483134206612e-05,
      "loss": 0.1117,
      "step": 5300
    },
    {
      "epoch": 0.25670553236409,
      "grad_norm": 0.7353618741035461,
      "learning_rate": 1.486684899956816e-05,
      "loss": 0.1226,
      "step": 5350
    },
    {
      "epoch": 0.25910464948898804,
      "grad_norm": 0.8704533576965332,
      "learning_rate": 1.48188666570702e-05,
      "loss": 0.0928,
      "step": 5400
    },
    {
      "epoch": 0.2615037666138861,
      "grad_norm": 2.5235016345977783,
      "learning_rate": 1.4770884314572238e-05,
      "loss": 0.1049,
      "step": 5450
    },
    {
      "epoch": 0.2639028837387841,
      "grad_norm": 1.996590495109558,
      "learning_rate": 1.4722901972074277e-05,
      "loss": 0.1235,
      "step": 5500
    },
    {
      "epoch": 0.26630200086368216,
      "grad_norm": 1.9517556428909302,
      "learning_rate": 1.4674919629576316e-05,
      "loss": 0.1549,
      "step": 5550
    },
    {
      "epoch": 0.2687011179885802,
      "grad_norm": 0.9450055360794067,
      "learning_rate": 1.4626937287078355e-05,
      "loss": 0.1522,
      "step": 5600
    },
    {
      "epoch": 0.27110023511347825,
      "grad_norm": 1.6962636709213257,
      "learning_rate": 1.4578954944580395e-05,
      "loss": 0.1191,
      "step": 5650
    },
    {
      "epoch": 0.2734993522383763,
      "grad_norm": 2.132260799407959,
      "learning_rate": 1.4530972602082434e-05,
      "loss": 0.1224,
      "step": 5700
    },
    {
      "epoch": 0.27589846936327433,
      "grad_norm": 0.06172797456383705,
      "learning_rate": 1.4482990259584474e-05,
      "loss": 0.1245,
      "step": 5750
    },
    {
      "epoch": 0.2782975864881724,
      "grad_norm": 2.4597740173339844,
      "learning_rate": 1.4435007917086515e-05,
      "loss": 0.1224,
      "step": 5800
    },
    {
      "epoch": 0.28069670361307036,
      "grad_norm": 1.079833745956421,
      "learning_rate": 1.4387025574588554e-05,
      "loss": 0.1024,
      "step": 5850
    },
    {
      "epoch": 0.2830958207379684,
      "grad_norm": 2.138303756713867,
      "learning_rate": 1.4339043232090592e-05,
      "loss": 0.1056,
      "step": 5900
    },
    {
      "epoch": 0.28549493786286645,
      "grad_norm": 1.6653165817260742,
      "learning_rate": 1.4291060889592631e-05,
      "loss": 0.0937,
      "step": 5950
    },
    {
      "epoch": 0.2878940549877645,
      "grad_norm": 69.82196044921875,
      "learning_rate": 1.4243078547094671e-05,
      "loss": 0.1189,
      "step": 6000
    },
    {
      "epoch": 0.29029317211266253,
      "grad_norm": 29.544221878051758,
      "learning_rate": 1.419509620459671e-05,
      "loss": 0.1417,
      "step": 6050
    },
    {
      "epoch": 0.2926922892375606,
      "grad_norm": 1.2301974296569824,
      "learning_rate": 1.4147113862098749e-05,
      "loss": 0.1135,
      "step": 6100
    },
    {
      "epoch": 0.2950914063624586,
      "grad_norm": 1.9036290645599365,
      "learning_rate": 1.4099131519600788e-05,
      "loss": 0.1085,
      "step": 6150
    },
    {
      "epoch": 0.29749052348735666,
      "grad_norm": 1.4854178428649902,
      "learning_rate": 1.4051149177102828e-05,
      "loss": 0.0979,
      "step": 6200
    },
    {
      "epoch": 0.2998896406122547,
      "grad_norm": 4.454460620880127,
      "learning_rate": 1.4003166834604867e-05,
      "loss": 0.1135,
      "step": 6250
    },
    {
      "epoch": 0.30228875773715275,
      "grad_norm": 1.1844983100891113,
      "learning_rate": 1.3955184492106906e-05,
      "loss": 0.1427,
      "step": 6300
    },
    {
      "epoch": 0.3046878748620508,
      "grad_norm": 0.01995999366044998,
      "learning_rate": 1.3907202149608944e-05,
      "loss": 0.1057,
      "step": 6350
    },
    {
      "epoch": 0.3070869919869488,
      "grad_norm": 1.4376686811447144,
      "learning_rate": 1.3859219807110985e-05,
      "loss": 0.1203,
      "step": 6400
    },
    {
      "epoch": 0.3094861091118468,
      "grad_norm": 0.9683465361595154,
      "learning_rate": 1.3811237464613024e-05,
      "loss": 0.0768,
      "step": 6450
    },
    {
      "epoch": 0.31188522623674486,
      "grad_norm": 0.021463381126523018,
      "learning_rate": 1.3763255122115062e-05,
      "loss": 0.0929,
      "step": 6500
    },
    {
      "epoch": 0.3142843433616429,
      "grad_norm": 1.1779999732971191,
      "learning_rate": 1.3715272779617101e-05,
      "loss": 0.1392,
      "step": 6550
    },
    {
      "epoch": 0.31668346048654095,
      "grad_norm": 2.81107234954834,
      "learning_rate": 1.366729043711914e-05,
      "loss": 0.0976,
      "step": 6600
    },
    {
      "epoch": 0.319082577611439,
      "grad_norm": 1.8631936311721802,
      "learning_rate": 1.361930809462118e-05,
      "loss": 0.1152,
      "step": 6650
    },
    {
      "epoch": 0.32148169473633703,
      "grad_norm": 2.5438637733459473,
      "learning_rate": 1.3571325752123219e-05,
      "loss": 0.0988,
      "step": 6700
    },
    {
      "epoch": 0.3238808118612351,
      "grad_norm": 0.9851220846176147,
      "learning_rate": 1.3523343409625258e-05,
      "loss": 0.097,
      "step": 6750
    },
    {
      "epoch": 0.3262799289861331,
      "grad_norm": 33.647857666015625,
      "learning_rate": 1.3475361067127296e-05,
      "loss": 0.1096,
      "step": 6800
    },
    {
      "epoch": 0.32867904611103116,
      "grad_norm": 0.010043956339359283,
      "learning_rate": 1.3427378724629339e-05,
      "loss": 0.1007,
      "step": 6850
    },
    {
      "epoch": 0.3310781632359292,
      "grad_norm": 1.1906299591064453,
      "learning_rate": 1.3379396382131377e-05,
      "loss": 0.0939,
      "step": 6900
    },
    {
      "epoch": 0.3334772803608272,
      "grad_norm": 0.815740168094635,
      "learning_rate": 1.3331414039633416e-05,
      "loss": 0.1017,
      "step": 6950
    },
    {
      "epoch": 0.33587639748572523,
      "grad_norm": 0.01378406211733818,
      "learning_rate": 1.3283431697135457e-05,
      "loss": 0.111,
      "step": 7000
    },
    {
      "epoch": 0.3382755146106233,
      "grad_norm": 0.029802698642015457,
      "learning_rate": 1.3235449354637495e-05,
      "loss": 0.0957,
      "step": 7050
    },
    {
      "epoch": 0.3406746317355213,
      "grad_norm": 0.014850790612399578,
      "learning_rate": 1.3187467012139534e-05,
      "loss": 0.0874,
      "step": 7100
    },
    {
      "epoch": 0.34307374886041936,
      "grad_norm": 33.62438201904297,
      "learning_rate": 1.3139484669641573e-05,
      "loss": 0.1276,
      "step": 7150
    },
    {
      "epoch": 0.3454728659853174,
      "grad_norm": 103.96926879882812,
      "learning_rate": 1.3091502327143613e-05,
      "loss": 0.145,
      "step": 7200
    },
    {
      "epoch": 0.34787198311021544,
      "grad_norm": 2.967495918273926,
      "learning_rate": 1.3043519984645652e-05,
      "loss": 0.1293,
      "step": 7250
    },
    {
      "epoch": 0.3502711002351135,
      "grad_norm": 2.3080544471740723,
      "learning_rate": 1.299553764214769e-05,
      "loss": 0.0838,
      "step": 7300
    },
    {
      "epoch": 0.35267021736001153,
      "grad_norm": 0.01034510601311922,
      "learning_rate": 1.294755529964973e-05,
      "loss": 0.08,
      "step": 7350
    },
    {
      "epoch": 0.35506933448490957,
      "grad_norm": 1.038744568824768,
      "learning_rate": 1.289957295715177e-05,
      "loss": 0.1,
      "step": 7400
    },
    {
      "epoch": 0.3574684516098076,
      "grad_norm": 1.4824254512786865,
      "learning_rate": 1.2851590614653809e-05,
      "loss": 0.1151,
      "step": 7450
    },
    {
      "epoch": 0.3598675687347056,
      "grad_norm": 8.814380645751953,
      "learning_rate": 1.2803608272155847e-05,
      "loss": 0.1111,
      "step": 7500
    },
    {
      "epoch": 0.36226668585960364,
      "grad_norm": 1.1961876153945923,
      "learning_rate": 1.2755625929657886e-05,
      "loss": 0.121,
      "step": 7550
    },
    {
      "epoch": 0.3646658029845017,
      "grad_norm": 4.177436351776123,
      "learning_rate": 1.2707643587159927e-05,
      "loss": 0.1084,
      "step": 7600
    },
    {
      "epoch": 0.36706492010939973,
      "grad_norm": 1.0832903385162354,
      "learning_rate": 1.2659661244661965e-05,
      "loss": 0.1061,
      "step": 7650
    },
    {
      "epoch": 0.36946403723429777,
      "grad_norm": 1.64530611038208,
      "learning_rate": 1.2611678902164004e-05,
      "loss": 0.1116,
      "step": 7700
    },
    {
      "epoch": 0.3718631543591958,
      "grad_norm": 58.86606979370117,
      "learning_rate": 1.2563696559666043e-05,
      "loss": 0.0964,
      "step": 7750
    },
    {
      "epoch": 0.37426227148409386,
      "grad_norm": 2.998676061630249,
      "learning_rate": 1.2515714217168081e-05,
      "loss": 0.1132,
      "step": 7800
    },
    {
      "epoch": 0.3766613886089919,
      "grad_norm": 0.8313689231872559,
      "learning_rate": 1.2467731874670122e-05,
      "loss": 0.1076,
      "step": 7850
    },
    {
      "epoch": 0.37906050573388994,
      "grad_norm": 33.80426788330078,
      "learning_rate": 1.241974953217216e-05,
      "loss": 0.1158,
      "step": 7900
    },
    {
      "epoch": 0.381459622858788,
      "grad_norm": 0.6033414602279663,
      "learning_rate": 1.2371767189674203e-05,
      "loss": 0.0936,
      "step": 7950
    },
    {
      "epoch": 0.383858739983686,
      "grad_norm": 1.3734287023544312,
      "learning_rate": 1.2323784847176242e-05,
      "loss": 0.0992,
      "step": 8000
    },
    {
      "epoch": 0.38625785710858407,
      "grad_norm": 0.9170442223548889,
      "learning_rate": 1.227580250467828e-05,
      "loss": 0.1082,
      "step": 8050
    },
    {
      "epoch": 0.38865697423348206,
      "grad_norm": 0.02837519720196724,
      "learning_rate": 1.2227820162180319e-05,
      "loss": 0.1083,
      "step": 8100
    },
    {
      "epoch": 0.3910560913583801,
      "grad_norm": 1.9346543550491333,
      "learning_rate": 1.2179837819682358e-05,
      "loss": 0.1068,
      "step": 8150
    },
    {
      "epoch": 0.39345520848327814,
      "grad_norm": 0.7005573511123657,
      "learning_rate": 1.2131855477184398e-05,
      "loss": 0.0832,
      "step": 8200
    },
    {
      "epoch": 0.3958543256081762,
      "grad_norm": 1.2112592458724976,
      "learning_rate": 1.2083873134686437e-05,
      "loss": 0.0871,
      "step": 8250
    },
    {
      "epoch": 0.3982534427330742,
      "grad_norm": 1.3239234685897827,
      "learning_rate": 1.2035890792188476e-05,
      "loss": 0.0916,
      "step": 8300
    },
    {
      "epoch": 0.40065255985797227,
      "grad_norm": 1.744840383529663,
      "learning_rate": 1.1987908449690514e-05,
      "loss": 0.1129,
      "step": 8350
    },
    {
      "epoch": 0.4030516769828703,
      "grad_norm": 5.340917587280273,
      "learning_rate": 1.1939926107192555e-05,
      "loss": 0.1115,
      "step": 8400
    },
    {
      "epoch": 0.40545079410776835,
      "grad_norm": 1.089748501777649,
      "learning_rate": 1.1891943764694594e-05,
      "loss": 0.0951,
      "step": 8450
    },
    {
      "epoch": 0.4078499112326664,
      "grad_norm": 1.8345493078231812,
      "learning_rate": 1.1843961422196632e-05,
      "loss": 0.1099,
      "step": 8500
    },
    {
      "epoch": 0.41024902835756444,
      "grad_norm": 1.6010364294052124,
      "learning_rate": 1.1795979079698671e-05,
      "loss": 0.1172,
      "step": 8550
    },
    {
      "epoch": 0.4126481454824625,
      "grad_norm": 0.016519997268915176,
      "learning_rate": 1.1747996737200712e-05,
      "loss": 0.1112,
      "step": 8600
    },
    {
      "epoch": 0.41504726260736047,
      "grad_norm": 2.732027053833008,
      "learning_rate": 1.170001439470275e-05,
      "loss": 0.1085,
      "step": 8650
    },
    {
      "epoch": 0.4174463797322585,
      "grad_norm": 1.192873239517212,
      "learning_rate": 1.1652032052204789e-05,
      "loss": 0.1127,
      "step": 8700
    },
    {
      "epoch": 0.41984549685715655,
      "grad_norm": 1.868079662322998,
      "learning_rate": 1.1604049709706828e-05,
      "loss": 0.1057,
      "step": 8750
    },
    {
      "epoch": 0.4222446139820546,
      "grad_norm": 1.9892460107803345,
      "learning_rate": 1.1556067367208868e-05,
      "loss": 0.1048,
      "step": 8800
    },
    {
      "epoch": 0.42464373110695264,
      "grad_norm": 1.0821613073349,
      "learning_rate": 1.1508085024710907e-05,
      "loss": 0.1034,
      "step": 8850
    },
    {
      "epoch": 0.4270428482318507,
      "grad_norm": 2.0141215324401855,
      "learning_rate": 1.1460102682212946e-05,
      "loss": 0.1062,
      "step": 8900
    },
    {
      "epoch": 0.4294419653567487,
      "grad_norm": 1.6246532201766968,
      "learning_rate": 1.1412120339714984e-05,
      "loss": 0.0931,
      "step": 8950
    },
    {
      "epoch": 0.43184108248164677,
      "grad_norm": 1.3021825551986694,
      "learning_rate": 1.1364137997217023e-05,
      "loss": 0.1016,
      "step": 9000
    },
    {
      "epoch": 0.4342401996065448,
      "grad_norm": 0.80918949842453,
      "learning_rate": 1.1316155654719065e-05,
      "loss": 0.0934,
      "step": 9050
    },
    {
      "epoch": 0.43663931673144285,
      "grad_norm": 9.128043174743652,
      "learning_rate": 1.1268173312221104e-05,
      "loss": 0.1181,
      "step": 9100
    },
    {
      "epoch": 0.4390384338563409,
      "grad_norm": 1.5744318962097168,
      "learning_rate": 1.1220190969723145e-05,
      "loss": 0.0802,
      "step": 9150
    },
    {
      "epoch": 0.4414375509812389,
      "grad_norm": 0.7765730023384094,
      "learning_rate": 1.1172208627225183e-05,
      "loss": 0.1181,
      "step": 9200
    },
    {
      "epoch": 0.4438366681061369,
      "grad_norm": 1.3601610660552979,
      "learning_rate": 1.1124226284727222e-05,
      "loss": 0.0868,
      "step": 9250
    },
    {
      "epoch": 0.44623578523103496,
      "grad_norm": 1.1519979238510132,
      "learning_rate": 1.107624394222926e-05,
      "loss": 0.1408,
      "step": 9300
    },
    {
      "epoch": 0.448634902355933,
      "grad_norm": 0.6810621619224548,
      "learning_rate": 1.10282615997313e-05,
      "loss": 0.0896,
      "step": 9350
    },
    {
      "epoch": 0.45103401948083105,
      "grad_norm": 1.4823508262634277,
      "learning_rate": 1.098027925723334e-05,
      "loss": 0.0795,
      "step": 9400
    },
    {
      "epoch": 0.4534331366057291,
      "grad_norm": 0.8861111402511597,
      "learning_rate": 1.0932296914735379e-05,
      "loss": 0.096,
      "step": 9450
    },
    {
      "epoch": 0.45583225373062713,
      "grad_norm": 1.4686331748962402,
      "learning_rate": 1.0884314572237417e-05,
      "loss": 0.0836,
      "step": 9500
    },
    {
      "epoch": 0.4582313708555252,
      "grad_norm": 1.4483846426010132,
      "learning_rate": 1.0836332229739456e-05,
      "loss": 0.0896,
      "step": 9550
    },
    {
      "epoch": 0.4606304879804232,
      "grad_norm": 1.285488486289978,
      "learning_rate": 1.0788349887241497e-05,
      "loss": 0.099,
      "step": 9600
    },
    {
      "epoch": 0.46302960510532126,
      "grad_norm": 1.1509602069854736,
      "learning_rate": 1.0740367544743535e-05,
      "loss": 0.1381,
      "step": 9650
    },
    {
      "epoch": 0.4654287222302193,
      "grad_norm": 1.0880415439605713,
      "learning_rate": 1.0692385202245574e-05,
      "loss": 0.1232,
      "step": 9700
    },
    {
      "epoch": 0.4678278393551173,
      "grad_norm": 1.1854265928268433,
      "learning_rate": 1.0644402859747613e-05,
      "loss": 0.1287,
      "step": 9750
    },
    {
      "epoch": 0.47022695648001533,
      "grad_norm": 1.1350749731063843,
      "learning_rate": 1.0596420517249653e-05,
      "loss": 0.1091,
      "step": 9800
    },
    {
      "epoch": 0.4726260736049134,
      "grad_norm": 0.9901478886604309,
      "learning_rate": 1.0548438174751692e-05,
      "loss": 0.0725,
      "step": 9850
    },
    {
      "epoch": 0.4750251907298114,
      "grad_norm": 0.7690473198890686,
      "learning_rate": 1.050045583225373e-05,
      "loss": 0.1064,
      "step": 9900
    },
    {
      "epoch": 0.47742430785470946,
      "grad_norm": 1.2981995344161987,
      "learning_rate": 1.045247348975577e-05,
      "loss": 0.0815,
      "step": 9950
    },
    {
      "epoch": 0.4798234249796075,
      "grad_norm": 2.461387872695923,
      "learning_rate": 1.040449114725781e-05,
      "loss": 0.1149,
      "step": 10000
    },
    {
      "epoch": 0.48222254210450555,
      "grad_norm": 0.5662322640419006,
      "learning_rate": 1.0356508804759849e-05,
      "loss": 0.1057,
      "step": 10050
    },
    {
      "epoch": 0.4846216592294036,
      "grad_norm": 0.9742369055747986,
      "learning_rate": 1.0308526462261887e-05,
      "loss": 0.1051,
      "step": 10100
    },
    {
      "epoch": 0.48702077635430163,
      "grad_norm": 0.03128673508763313,
      "learning_rate": 1.0260544119763926e-05,
      "loss": 0.1223,
      "step": 10150
    },
    {
      "epoch": 0.4894198934791997,
      "grad_norm": 0.006991918198764324,
      "learning_rate": 1.0212561777265968e-05,
      "loss": 0.0908,
      "step": 10200
    },
    {
      "epoch": 0.4918190106040977,
      "grad_norm": 1.642903447151184,
      "learning_rate": 1.0164579434768007e-05,
      "loss": 0.1058,
      "step": 10250
    },
    {
      "epoch": 0.4942181277289957,
      "grad_norm": 1.9089386463165283,
      "learning_rate": 1.0116597092270046e-05,
      "loss": 0.1063,
      "step": 10300
    },
    {
      "epoch": 0.49661724485389375,
      "grad_norm": 1.668326735496521,
      "learning_rate": 1.0068614749772085e-05,
      "loss": 0.0746,
      "step": 10350
    },
    {
      "epoch": 0.4990163619787918,
      "grad_norm": 0.015245519578456879,
      "learning_rate": 1.0020632407274125e-05,
      "loss": 0.0873,
      "step": 10400
    },
    {
      "epoch": 0.5014154791036899,
      "grad_norm": 1.7360798120498657,
      "learning_rate": 9.972650064776164e-06,
      "loss": 0.1225,
      "step": 10450
    },
    {
      "epoch": 0.5038145962285879,
      "grad_norm": 2.440547227859497,
      "learning_rate": 9.924667722278203e-06,
      "loss": 0.1045,
      "step": 10500
    },
    {
      "epoch": 0.506213713353486,
      "grad_norm": 0.8576765060424805,
      "learning_rate": 9.876685379780241e-06,
      "loss": 0.1289,
      "step": 10550
    },
    {
      "epoch": 0.5086128304783839,
      "grad_norm": 1.2905603647232056,
      "learning_rate": 9.828703037282282e-06,
      "loss": 0.1112,
      "step": 10600
    },
    {
      "epoch": 0.511011947603282,
      "grad_norm": 1.9132198095321655,
      "learning_rate": 9.78072069478432e-06,
      "loss": 0.0971,
      "step": 10650
    },
    {
      "epoch": 0.51341106472818,
      "grad_norm": 1.1593444347381592,
      "learning_rate": 9.73273835228636e-06,
      "loss": 0.0872,
      "step": 10700
    },
    {
      "epoch": 0.515810181853078,
      "grad_norm": 0.006880328990519047,
      "learning_rate": 9.684756009788398e-06,
      "loss": 0.0833,
      "step": 10750
    },
    {
      "epoch": 0.5182092989779761,
      "grad_norm": 1.4379764795303345,
      "learning_rate": 9.636773667290438e-06,
      "loss": 0.1089,
      "step": 10800
    },
    {
      "epoch": 0.5206084161028741,
      "grad_norm": 0.0061031184159219265,
      "learning_rate": 9.588791324792477e-06,
      "loss": 0.0941,
      "step": 10850
    },
    {
      "epoch": 0.5230075332277722,
      "grad_norm": 0.8512915372848511,
      "learning_rate": 9.540808982294516e-06,
      "loss": 0.1119,
      "step": 10900
    },
    {
      "epoch": 0.5254066503526702,
      "grad_norm": 1.7811596393585205,
      "learning_rate": 9.492826639796555e-06,
      "loss": 0.1041,
      "step": 10950
    },
    {
      "epoch": 0.5278057674775682,
      "grad_norm": 0.800888180732727,
      "learning_rate": 9.444844297298595e-06,
      "loss": 0.1197,
      "step": 11000
    },
    {
      "epoch": 0.5302048846024663,
      "grad_norm": 1.1576193571090698,
      "learning_rate": 9.396861954800634e-06,
      "loss": 0.0952,
      "step": 11050
    },
    {
      "epoch": 0.5326040017273643,
      "grad_norm": 0.008696796372532845,
      "learning_rate": 9.348879612302674e-06,
      "loss": 0.1213,
      "step": 11100
    },
    {
      "epoch": 0.5350031188522624,
      "grad_norm": 1.0948173999786377,
      "learning_rate": 9.300897269804713e-06,
      "loss": 0.1444,
      "step": 11150
    },
    {
      "epoch": 0.5374022359771604,
      "grad_norm": 0.9187643527984619,
      "learning_rate": 9.252914927306752e-06,
      "loss": 0.095,
      "step": 11200
    },
    {
      "epoch": 0.5398013531020585,
      "grad_norm": 1.2066521644592285,
      "learning_rate": 9.20493258480879e-06,
      "loss": 0.1027,
      "step": 11250
    },
    {
      "epoch": 0.5422004702269565,
      "grad_norm": 0.9167560935020447,
      "learning_rate": 9.156950242310831e-06,
      "loss": 0.0768,
      "step": 11300
    },
    {
      "epoch": 0.5445995873518545,
      "grad_norm": 0.008570017293095589,
      "learning_rate": 9.10896789981287e-06,
      "loss": 0.0909,
      "step": 11350
    },
    {
      "epoch": 0.5469987044767526,
      "grad_norm": 1.1456633806228638,
      "learning_rate": 9.060985557314908e-06,
      "loss": 0.0925,
      "step": 11400
    },
    {
      "epoch": 0.5493978216016506,
      "grad_norm": 0.007653943728655577,
      "learning_rate": 9.013003214816947e-06,
      "loss": 0.1071,
      "step": 11450
    },
    {
      "epoch": 0.5517969387265487,
      "grad_norm": 2.527344226837158,
      "learning_rate": 8.965020872318988e-06,
      "loss": 0.1004,
      "step": 11500
    },
    {
      "epoch": 0.5541960558514467,
      "grad_norm": 2.0682764053344727,
      "learning_rate": 8.917038529821026e-06,
      "loss": 0.1125,
      "step": 11550
    },
    {
      "epoch": 0.5565951729763448,
      "grad_norm": 0.7498477101325989,
      "learning_rate": 8.869056187323067e-06,
      "loss": 0.0973,
      "step": 11600
    },
    {
      "epoch": 0.5589942901012428,
      "grad_norm": 0.9513236284255981,
      "learning_rate": 8.821073844825105e-06,
      "loss": 0.0885,
      "step": 11650
    },
    {
      "epoch": 0.5613934072261407,
      "grad_norm": 1.1886934041976929,
      "learning_rate": 8.773091502327144e-06,
      "loss": 0.0939,
      "step": 11700
    },
    {
      "epoch": 0.5637925243510388,
      "grad_norm": 4.862268924713135,
      "learning_rate": 8.725109159829183e-06,
      "loss": 0.0933,
      "step": 11750
    },
    {
      "epoch": 0.5661916414759368,
      "grad_norm": 0.9598628878593445,
      "learning_rate": 8.677126817331223e-06,
      "loss": 0.1102,
      "step": 11800
    },
    {
      "epoch": 0.5685907586008349,
      "grad_norm": 1.11598539352417,
      "learning_rate": 8.629144474833262e-06,
      "loss": 0.0915,
      "step": 11850
    },
    {
      "epoch": 0.5709898757257329,
      "grad_norm": 1.352508544921875,
      "learning_rate": 8.581162132335301e-06,
      "loss": 0.096,
      "step": 11900
    },
    {
      "epoch": 0.5733889928506309,
      "grad_norm": 2.5889363288879395,
      "learning_rate": 8.53317978983734e-06,
      "loss": 0.097,
      "step": 11950
    },
    {
      "epoch": 0.575788109975529,
      "grad_norm": 1.1970475912094116,
      "learning_rate": 8.48519744733938e-06,
      "loss": 0.079,
      "step": 12000
    },
    {
      "epoch": 0.578187227100427,
      "grad_norm": 0.0034590745344758034,
      "learning_rate": 8.437215104841419e-06,
      "loss": 0.0917,
      "step": 12050
    },
    {
      "epoch": 0.5805863442253251,
      "grad_norm": 0.17554324865341187,
      "learning_rate": 8.38923276234346e-06,
      "loss": 0.089,
      "step": 12100
    },
    {
      "epoch": 0.5829854613502231,
      "grad_norm": 1.1225991249084473,
      "learning_rate": 8.341250419845498e-06,
      "loss": 0.0913,
      "step": 12150
    },
    {
      "epoch": 0.5853845784751212,
      "grad_norm": 1.5905510187149048,
      "learning_rate": 8.293268077347537e-06,
      "loss": 0.0915,
      "step": 12200
    },
    {
      "epoch": 0.5877836956000192,
      "grad_norm": 1.4559681415557861,
      "learning_rate": 8.245285734849576e-06,
      "loss": 0.0858,
      "step": 12250
    },
    {
      "epoch": 0.5901828127249172,
      "grad_norm": 0.9885453581809998,
      "learning_rate": 8.197303392351616e-06,
      "loss": 0.0982,
      "step": 12300
    },
    {
      "epoch": 0.5925819298498153,
      "grad_norm": 0.02732807584106922,
      "learning_rate": 8.149321049853655e-06,
      "loss": 0.1024,
      "step": 12350
    },
    {
      "epoch": 0.5949810469747133,
      "grad_norm": 0.9580175280570984,
      "learning_rate": 8.101338707355693e-06,
      "loss": 0.1019,
      "step": 12400
    },
    {
      "epoch": 0.5973801640996114,
      "grad_norm": 3.336625337600708,
      "learning_rate": 8.053356364857732e-06,
      "loss": 0.0805,
      "step": 12450
    },
    {
      "epoch": 0.5997792812245094,
      "grad_norm": 0.924948513507843,
      "learning_rate": 8.005374022359773e-06,
      "loss": 0.1114,
      "step": 12500
    },
    {
      "epoch": 0.6021783983494075,
      "grad_norm": 5.320333003997803,
      "learning_rate": 7.957391679861811e-06,
      "loss": 0.1137,
      "step": 12550
    },
    {
      "epoch": 0.6045775154743055,
      "grad_norm": 40.52354049682617,
      "learning_rate": 7.90940933736385e-06,
      "loss": 0.1041,
      "step": 12600
    },
    {
      "epoch": 0.6069766325992035,
      "grad_norm": 0.004384483676403761,
      "learning_rate": 7.861426994865889e-06,
      "loss": 0.109,
      "step": 12650
    },
    {
      "epoch": 0.6093757497241016,
      "grad_norm": 1.5276411771774292,
      "learning_rate": 7.81344465236793e-06,
      "loss": 0.1222,
      "step": 12700
    },
    {
      "epoch": 0.6117748668489996,
      "grad_norm": 8.984333038330078,
      "learning_rate": 7.765462309869968e-06,
      "loss": 0.108,
      "step": 12750
    },
    {
      "epoch": 0.6141739839738976,
      "grad_norm": 1.4156936407089233,
      "learning_rate": 7.717479967372008e-06,
      "loss": 0.0947,
      "step": 12800
    },
    {
      "epoch": 0.6165731010987956,
      "grad_norm": 1.3186858892440796,
      "learning_rate": 7.669497624874047e-06,
      "loss": 0.0818,
      "step": 12850
    },
    {
      "epoch": 0.6189722182236936,
      "grad_norm": 1.7005118131637573,
      "learning_rate": 7.621515282376086e-06,
      "loss": 0.1227,
      "step": 12900
    },
    {
      "epoch": 0.6213713353485917,
      "grad_norm": 5.169679641723633,
      "learning_rate": 7.5735329398781256e-06,
      "loss": 0.0928,
      "step": 12950
    },
    {
      "epoch": 0.6237704524734897,
      "grad_norm": 0.00225523067638278,
      "learning_rate": 7.525550597380164e-06,
      "loss": 0.1151,
      "step": 13000
    },
    {
      "epoch": 0.6261695695983878,
      "grad_norm": 0.8801671266555786,
      "learning_rate": 7.477568254882204e-06,
      "loss": 0.1192,
      "step": 13050
    },
    {
      "epoch": 0.6285686867232858,
      "grad_norm": 5.9025397300720215,
      "learning_rate": 7.429585912384243e-06,
      "loss": 0.0833,
      "step": 13100
    },
    {
      "epoch": 0.6309678038481839,
      "grad_norm": 1.549960970878601,
      "learning_rate": 7.381603569886282e-06,
      "loss": 0.0713,
      "step": 13150
    },
    {
      "epoch": 0.6333669209730819,
      "grad_norm": 1.3899257183074951,
      "learning_rate": 7.333621227388321e-06,
      "loss": 0.0851,
      "step": 13200
    },
    {
      "epoch": 0.6357660380979799,
      "grad_norm": 1.1450505256652832,
      "learning_rate": 7.285638884890361e-06,
      "loss": 0.0956,
      "step": 13250
    },
    {
      "epoch": 0.638165155222878,
      "grad_norm": 0.967523992061615,
      "learning_rate": 7.2376565423924e-06,
      "loss": 0.0838,
      "step": 13300
    },
    {
      "epoch": 0.640564272347776,
      "grad_norm": 0.0059617566876113415,
      "learning_rate": 7.18967419989444e-06,
      "loss": 0.0679,
      "step": 13350
    },
    {
      "epoch": 0.6429633894726741,
      "grad_norm": 1.7413556575775146,
      "learning_rate": 7.1416918573964785e-06,
      "loss": 0.1251,
      "step": 13400
    },
    {
      "epoch": 0.6453625065975721,
      "grad_norm": 6.2201313972473145,
      "learning_rate": 7.093709514898518e-06,
      "loss": 0.0988,
      "step": 13450
    },
    {
      "epoch": 0.6477616237224701,
      "grad_norm": 1.3853678703308105,
      "learning_rate": 7.045727172400557e-06,
      "loss": 0.0893,
      "step": 13500
    },
    {
      "epoch": 0.6501607408473682,
      "grad_norm": 0.8565723896026611,
      "learning_rate": 6.9977448299025964e-06,
      "loss": 0.0992,
      "step": 13550
    },
    {
      "epoch": 0.6525598579722662,
      "grad_norm": 0.03008650243282318,
      "learning_rate": 6.949762487404635e-06,
      "loss": 0.0753,
      "step": 13600
    },
    {
      "epoch": 0.6549589750971643,
      "grad_norm": 1.1204495429992676,
      "learning_rate": 6.901780144906675e-06,
      "loss": 0.0959,
      "step": 13650
    },
    {
      "epoch": 0.6573580922220623,
      "grad_norm": 0.7725280523300171,
      "learning_rate": 6.8537978024087135e-06,
      "loss": 0.0738,
      "step": 13700
    },
    {
      "epoch": 0.6597572093469604,
      "grad_norm": 1.0992813110351562,
      "learning_rate": 6.805815459910753e-06,
      "loss": 0.0762,
      "step": 13750
    },
    {
      "epoch": 0.6621563264718584,
      "grad_norm": 1.3280335664749146,
      "learning_rate": 6.7578331174127935e-06,
      "loss": 0.0875,
      "step": 13800
    },
    {
      "epoch": 0.6645554435967564,
      "grad_norm": 1.4064958095550537,
      "learning_rate": 6.709850774914832e-06,
      "loss": 0.0922,
      "step": 13850
    },
    {
      "epoch": 0.6669545607216544,
      "grad_norm": 3.2581522464752197,
      "learning_rate": 6.661868432416871e-06,
      "loss": 0.096,
      "step": 13900
    },
    {
      "epoch": 0.6693536778465524,
      "grad_norm": 1.0534837245941162,
      "learning_rate": 6.613886089918911e-06,
      "loss": 0.1255,
      "step": 13950
    },
    {
      "epoch": 0.6717527949714505,
      "grad_norm": 0.991981029510498,
      "learning_rate": 6.565903747420949e-06,
      "loss": 0.1015,
      "step": 14000
    },
    {
      "epoch": 0.6741519120963485,
      "grad_norm": 1.8908979892730713,
      "learning_rate": 6.517921404922989e-06,
      "loss": 0.092,
      "step": 14050
    },
    {
      "epoch": 0.6765510292212465,
      "grad_norm": 1.0838567018508911,
      "learning_rate": 6.469939062425028e-06,
      "loss": 0.0893,
      "step": 14100
    },
    {
      "epoch": 0.6789501463461446,
      "grad_norm": 0.004867145791649818,
      "learning_rate": 6.421956719927067e-06,
      "loss": 0.0967,
      "step": 14150
    },
    {
      "epoch": 0.6813492634710426,
      "grad_norm": 1.2263598442077637,
      "learning_rate": 6.373974377429106e-06,
      "loss": 0.0929,
      "step": 14200
    },
    {
      "epoch": 0.6837483805959407,
      "grad_norm": 0.01440497487783432,
      "learning_rate": 6.325992034931146e-06,
      "loss": 0.0809,
      "step": 14250
    },
    {
      "epoch": 0.6861474977208387,
      "grad_norm": 0.00378206605091691,
      "learning_rate": 6.278009692433184e-06,
      "loss": 0.0853,
      "step": 14300
    },
    {
      "epoch": 0.6885466148457368,
      "grad_norm": 0.009434722363948822,
      "learning_rate": 6.230027349935225e-06,
      "loss": 0.0765,
      "step": 14350
    },
    {
      "epoch": 0.6909457319706348,
      "grad_norm": 0.901878297328949,
      "learning_rate": 6.182045007437264e-06,
      "loss": 0.0821,
      "step": 14400
    },
    {
      "epoch": 0.6933448490955328,
      "grad_norm": 1.1529067754745483,
      "learning_rate": 6.134062664939303e-06,
      "loss": 0.0887,
      "step": 14450
    },
    {
      "epoch": 0.6957439662204309,
      "grad_norm": 0.8578082919120789,
      "learning_rate": 6.086080322441342e-06,
      "loss": 0.0938,
      "step": 14500
    },
    {
      "epoch": 0.6981430833453289,
      "grad_norm": 2.1827337741851807,
      "learning_rate": 6.0380979799433815e-06,
      "loss": 0.0879,
      "step": 14550
    },
    {
      "epoch": 0.700542200470227,
      "grad_norm": 1.073009967803955,
      "learning_rate": 5.99011563744542e-06,
      "loss": 0.0767,
      "step": 14600
    },
    {
      "epoch": 0.702941317595125,
      "grad_norm": 8.326745986938477,
      "learning_rate": 5.94213329494746e-06,
      "loss": 0.1058,
      "step": 14650
    },
    {
      "epoch": 0.7053404347200231,
      "grad_norm": 0.7772797346115112,
      "learning_rate": 5.8941509524494986e-06,
      "loss": 0.0708,
      "step": 14700
    },
    {
      "epoch": 0.7077395518449211,
      "grad_norm": 0.002769648330286145,
      "learning_rate": 5.846168609951538e-06,
      "loss": 0.0728,
      "step": 14750
    },
    {
      "epoch": 0.7101386689698191,
      "grad_norm": 0.004704718012362719,
      "learning_rate": 5.798186267453577e-06,
      "loss": 0.0775,
      "step": 14800
    },
    {
      "epoch": 0.7125377860947172,
      "grad_norm": 50.589786529541016,
      "learning_rate": 5.7502039249556165e-06,
      "loss": 0.0773,
      "step": 14850
    },
    {
      "epoch": 0.7149369032196152,
      "grad_norm": 35.190372467041016,
      "learning_rate": 5.702221582457657e-06,
      "loss": 0.1145,
      "step": 14900
    },
    {
      "epoch": 0.7173360203445133,
      "grad_norm": 2.0461747646331787,
      "learning_rate": 5.654239239959696e-06,
      "loss": 0.0935,
      "step": 14950
    },
    {
      "epoch": 0.7197351374694112,
      "grad_norm": 2.2579431533813477,
      "learning_rate": 5.606256897461735e-06,
      "loss": 0.0869,
      "step": 15000
    },
    {
      "epoch": 0.7221342545943092,
      "grad_norm": 1.4418854713439941,
      "learning_rate": 5.558274554963774e-06,
      "loss": 0.0818,
      "step": 15050
    },
    {
      "epoch": 0.7245333717192073,
      "grad_norm": 4.619683265686035,
      "learning_rate": 5.510292212465813e-06,
      "loss": 0.1035,
      "step": 15100
    },
    {
      "epoch": 0.7269324888441053,
      "grad_norm": 1.2162595987319946,
      "learning_rate": 5.462309869967852e-06,
      "loss": 0.1217,
      "step": 15150
    },
    {
      "epoch": 0.7293316059690034,
      "grad_norm": 5.209877014160156,
      "learning_rate": 5.414327527469891e-06,
      "loss": 0.074,
      "step": 15200
    },
    {
      "epoch": 0.7317307230939014,
      "grad_norm": 1.197742223739624,
      "learning_rate": 5.366345184971931e-06,
      "loss": 0.0878,
      "step": 15250
    },
    {
      "epoch": 0.7341298402187995,
      "grad_norm": 1.8604189157485962,
      "learning_rate": 5.3183628424739694e-06,
      "loss": 0.0914,
      "step": 15300
    },
    {
      "epoch": 0.7365289573436975,
      "grad_norm": 1.305836796760559,
      "learning_rate": 5.270380499976009e-06,
      "loss": 0.1186,
      "step": 15350
    },
    {
      "epoch": 0.7389280744685955,
      "grad_norm": 1.5763291120529175,
      "learning_rate": 5.222398157478048e-06,
      "loss": 0.0914,
      "step": 15400
    },
    {
      "epoch": 0.7413271915934936,
      "grad_norm": 1.3634570837020874,
      "learning_rate": 5.174415814980088e-06,
      "loss": 0.0836,
      "step": 15450
    },
    {
      "epoch": 0.7437263087183916,
      "grad_norm": 0.00577102554962039,
      "learning_rate": 5.126433472482128e-06,
      "loss": 0.0974,
      "step": 15500
    },
    {
      "epoch": 0.7461254258432897,
      "grad_norm": 1.2611701488494873,
      "learning_rate": 5.0784511299841665e-06,
      "loss": 0.1057,
      "step": 15550
    },
    {
      "epoch": 0.7485245429681877,
      "grad_norm": 1.7565717697143555,
      "learning_rate": 5.030468787486205e-06,
      "loss": 0.084,
      "step": 15600
    },
    {
      "epoch": 0.7509236600930858,
      "grad_norm": 1.9657164812088013,
      "learning_rate": 4.982486444988245e-06,
      "loss": 0.0948,
      "step": 15650
    },
    {
      "epoch": 0.7533227772179838,
      "grad_norm": 1.243920087814331,
      "learning_rate": 4.934504102490284e-06,
      "loss": 0.09,
      "step": 15700
    },
    {
      "epoch": 0.7557218943428818,
      "grad_norm": 1.3380242586135864,
      "learning_rate": 4.886521759992323e-06,
      "loss": 0.0991,
      "step": 15750
    },
    {
      "epoch": 0.7581210114677799,
      "grad_norm": 3.383584499359131,
      "learning_rate": 4.838539417494362e-06,
      "loss": 0.1172,
      "step": 15800
    },
    {
      "epoch": 0.7605201285926779,
      "grad_norm": 0.00472604064270854,
      "learning_rate": 4.790557074996402e-06,
      "loss": 0.0975,
      "step": 15850
    },
    {
      "epoch": 0.762919245717576,
      "grad_norm": 0.6236149072647095,
      "learning_rate": 4.742574732498441e-06,
      "loss": 0.0856,
      "step": 15900
    },
    {
      "epoch": 0.765318362842474,
      "grad_norm": 1.1516468524932861,
      "learning_rate": 4.69459239000048e-06,
      "loss": 0.0872,
      "step": 15950
    },
    {
      "epoch": 0.767717479967372,
      "grad_norm": 1.1802072525024414,
      "learning_rate": 4.6466100475025195e-06,
      "loss": 0.0852,
      "step": 16000
    },
    {
      "epoch": 0.7701165970922701,
      "grad_norm": 0.9404568672180176,
      "learning_rate": 4.598627705004558e-06,
      "loss": 0.0708,
      "step": 16050
    },
    {
      "epoch": 0.7725157142171681,
      "grad_norm": 1.2425618171691895,
      "learning_rate": 4.550645362506598e-06,
      "loss": 0.0945,
      "step": 16100
    },
    {
      "epoch": 0.7749148313420661,
      "grad_norm": 1.0351877212524414,
      "learning_rate": 4.502663020008637e-06,
      "loss": 0.0843,
      "step": 16150
    },
    {
      "epoch": 0.7773139484669641,
      "grad_norm": 0.8523932099342346,
      "learning_rate": 4.454680677510676e-06,
      "loss": 0.1063,
      "step": 16200
    },
    {
      "epoch": 0.7797130655918622,
      "grad_norm": 0.7928698062896729,
      "learning_rate": 4.406698335012716e-06,
      "loss": 0.093,
      "step": 16250
    },
    {
      "epoch": 0.7821121827167602,
      "grad_norm": 0.7324278354644775,
      "learning_rate": 4.3587159925147545e-06,
      "loss": 0.083,
      "step": 16300
    },
    {
      "epoch": 0.7845112998416582,
      "grad_norm": 1.1969375610351562,
      "learning_rate": 4.310733650016794e-06,
      "loss": 0.076,
      "step": 16350
    },
    {
      "epoch": 0.7869104169665563,
      "grad_norm": 1.2466473579406738,
      "learning_rate": 4.262751307518833e-06,
      "loss": 0.0902,
      "step": 16400
    },
    {
      "epoch": 0.7893095340914543,
      "grad_norm": 1.5859006643295288,
      "learning_rate": 4.214768965020873e-06,
      "loss": 0.1087,
      "step": 16450
    },
    {
      "epoch": 0.7917086512163524,
      "grad_norm": 0.8621366620063782,
      "learning_rate": 4.166786622522912e-06,
      "loss": 0.094,
      "step": 16500
    },
    {
      "epoch": 0.7941077683412504,
      "grad_norm": 1.5111632347106934,
      "learning_rate": 4.118804280024951e-06,
      "loss": 0.1071,
      "step": 16550
    },
    {
      "epoch": 0.7965068854661485,
      "grad_norm": 3.122036933898926,
      "learning_rate": 4.07082193752699e-06,
      "loss": 0.0976,
      "step": 16600
    },
    {
      "epoch": 0.7989060025910465,
      "grad_norm": 31.915122985839844,
      "learning_rate": 4.022839595029029e-06,
      "loss": 0.1139,
      "step": 16650
    },
    {
      "epoch": 0.8013051197159445,
      "grad_norm": 1.3628557920455933,
      "learning_rate": 3.9748572525310695e-06,
      "loss": 0.098,
      "step": 16700
    },
    {
      "epoch": 0.8037042368408426,
      "grad_norm": 1.2158708572387695,
      "learning_rate": 3.926874910033108e-06,
      "loss": 0.0993,
      "step": 16750
    },
    {
      "epoch": 0.8061033539657406,
      "grad_norm": 1.1326318979263306,
      "learning_rate": 3.878892567535147e-06,
      "loss": 0.1209,
      "step": 16800
    },
    {
      "epoch": 0.8085024710906387,
      "grad_norm": 2.4340007305145264,
      "learning_rate": 3.830910225037187e-06,
      "loss": 0.1116,
      "step": 16850
    },
    {
      "epoch": 0.8109015882155367,
      "grad_norm": 13.859671592712402,
      "learning_rate": 3.7829278825392258e-06,
      "loss": 0.0812,
      "step": 16900
    },
    {
      "epoch": 0.8133007053404347,
      "grad_norm": 2.7163429260253906,
      "learning_rate": 3.734945540041265e-06,
      "loss": 0.0851,
      "step": 16950
    },
    {
      "epoch": 0.8156998224653328,
      "grad_norm": 0.8122629523277283,
      "learning_rate": 3.6869631975433045e-06,
      "loss": 0.0891,
      "step": 17000
    },
    {
      "epoch": 0.8180989395902308,
      "grad_norm": 2.412841320037842,
      "learning_rate": 3.6389808550453437e-06,
      "loss": 0.1088,
      "step": 17050
    },
    {
      "epoch": 0.8204980567151289,
      "grad_norm": 1.7967777252197266,
      "learning_rate": 3.590998512547383e-06,
      "loss": 0.0743,
      "step": 17100
    },
    {
      "epoch": 0.8228971738400269,
      "grad_norm": 2.141331672668457,
      "learning_rate": 3.543016170049422e-06,
      "loss": 0.0901,
      "step": 17150
    },
    {
      "epoch": 0.825296290964925,
      "grad_norm": 1.0744953155517578,
      "learning_rate": 3.4950338275514612e-06,
      "loss": 0.1121,
      "step": 17200
    },
    {
      "epoch": 0.8276954080898229,
      "grad_norm": 1.4878809452056885,
      "learning_rate": 3.447051485053501e-06,
      "loss": 0.0823,
      "step": 17250
    },
    {
      "epoch": 0.8300945252147209,
      "grad_norm": 1.4486579895019531,
      "learning_rate": 3.39906914255554e-06,
      "loss": 0.0807,
      "step": 17300
    },
    {
      "epoch": 0.832493642339619,
      "grad_norm": 1.6188583374023438,
      "learning_rate": 3.351086800057579e-06,
      "loss": 0.0826,
      "step": 17350
    },
    {
      "epoch": 0.834892759464517,
      "grad_norm": 1.0290147066116333,
      "learning_rate": 3.3031044575596183e-06,
      "loss": 0.0936,
      "step": 17400
    },
    {
      "epoch": 0.8372918765894151,
      "grad_norm": 1.3214988708496094,
      "learning_rate": 3.2551221150616575e-06,
      "loss": 0.0949,
      "step": 17450
    },
    {
      "epoch": 0.8396909937143131,
      "grad_norm": 1.0941081047058105,
      "learning_rate": 3.2071397725636966e-06,
      "loss": 0.1222,
      "step": 17500
    },
    {
      "epoch": 0.8420901108392111,
      "grad_norm": 0.9297682642936707,
      "learning_rate": 3.1591574300657362e-06,
      "loss": 0.0924,
      "step": 17550
    },
    {
      "epoch": 0.8444892279641092,
      "grad_norm": 2.2196171283721924,
      "learning_rate": 3.1111750875677754e-06,
      "loss": 0.0872,
      "step": 17600
    },
    {
      "epoch": 0.8468883450890072,
      "grad_norm": 1.4328011274337769,
      "learning_rate": 3.0631927450698146e-06,
      "loss": 0.0897,
      "step": 17650
    },
    {
      "epoch": 0.8492874622139053,
      "grad_norm": 1.291082739830017,
      "learning_rate": 3.0152104025718537e-06,
      "loss": 0.0756,
      "step": 17700
    },
    {
      "epoch": 0.8516865793388033,
      "grad_norm": 1.7120518684387207,
      "learning_rate": 2.967228060073893e-06,
      "loss": 0.1063,
      "step": 17750
    },
    {
      "epoch": 0.8540856964637014,
      "grad_norm": 0.7660431861877441,
      "learning_rate": 2.9192457175759325e-06,
      "loss": 0.0672,
      "step": 17800
    },
    {
      "epoch": 0.8564848135885994,
      "grad_norm": 1.159547209739685,
      "learning_rate": 2.8712633750779717e-06,
      "loss": 0.094,
      "step": 17850
    },
    {
      "epoch": 0.8588839307134974,
      "grad_norm": 5.166666507720947,
      "learning_rate": 2.823281032580011e-06,
      "loss": 0.1088,
      "step": 17900
    },
    {
      "epoch": 0.8612830478383955,
      "grad_norm": 0.8371910452842712,
      "learning_rate": 2.77529869008205e-06,
      "loss": 0.098,
      "step": 17950
    },
    {
      "epoch": 0.8636821649632935,
      "grad_norm": 0.005333550274372101,
      "learning_rate": 2.727316347584089e-06,
      "loss": 0.0977,
      "step": 18000
    },
    {
      "epoch": 0.8660812820881916,
      "grad_norm": 0.019697504118084908,
      "learning_rate": 2.6793340050861283e-06,
      "loss": 0.0889,
      "step": 18050
    },
    {
      "epoch": 0.8684803992130896,
      "grad_norm": 0.9233031868934631,
      "learning_rate": 2.631351662588168e-06,
      "loss": 0.0972,
      "step": 18100
    },
    {
      "epoch": 0.8708795163379877,
      "grad_norm": 0.010453302413225174,
      "learning_rate": 2.583369320090207e-06,
      "loss": 0.0866,
      "step": 18150
    },
    {
      "epoch": 0.8732786334628857,
      "grad_norm": 0.8727567791938782,
      "learning_rate": 2.5353869775922463e-06,
      "loss": 0.1071,
      "step": 18200
    },
    {
      "epoch": 0.8756777505877837,
      "grad_norm": 1.1628490686416626,
      "learning_rate": 2.4874046350942854e-06,
      "loss": 0.0867,
      "step": 18250
    },
    {
      "epoch": 0.8780768677126818,
      "grad_norm": 0.003338081995025277,
      "learning_rate": 2.439422292596325e-06,
      "loss": 0.0756,
      "step": 18300
    },
    {
      "epoch": 0.8804759848375797,
      "grad_norm": 0.816198468208313,
      "learning_rate": 2.391439950098364e-06,
      "loss": 0.1005,
      "step": 18350
    },
    {
      "epoch": 0.8828751019624778,
      "grad_norm": 4.523688793182373,
      "learning_rate": 2.343457607600403e-06,
      "loss": 0.1223,
      "step": 18400
    },
    {
      "epoch": 0.8852742190873758,
      "grad_norm": 1.812146544456482,
      "learning_rate": 2.2954752651024425e-06,
      "loss": 0.1151,
      "step": 18450
    },
    {
      "epoch": 0.8876733362122738,
      "grad_norm": 2.200362205505371,
      "learning_rate": 2.2474929226044817e-06,
      "loss": 0.0821,
      "step": 18500
    },
    {
      "epoch": 0.8900724533371719,
      "grad_norm": 1.50260591506958,
      "learning_rate": 2.199510580106521e-06,
      "loss": 0.0864,
      "step": 18550
    },
    {
      "epoch": 0.8924715704620699,
      "grad_norm": 4.59011173248291,
      "learning_rate": 2.1515282376085605e-06,
      "loss": 0.1049,
      "step": 18600
    },
    {
      "epoch": 0.894870687586968,
      "grad_norm": 1.389858365058899,
      "learning_rate": 2.1035458951105996e-06,
      "loss": 0.0808,
      "step": 18650
    },
    {
      "epoch": 0.897269804711866,
      "grad_norm": 0.8556995987892151,
      "learning_rate": 2.055563552612639e-06,
      "loss": 0.0903,
      "step": 18700
    },
    {
      "epoch": 0.8996689218367641,
      "grad_norm": 0.006007722113281488,
      "learning_rate": 2.007581210114678e-06,
      "loss": 0.0867,
      "step": 18750
    },
    {
      "epoch": 0.9020680389616621,
      "grad_norm": 1.0875366926193237,
      "learning_rate": 1.959598867616717e-06,
      "loss": 0.0867,
      "step": 18800
    },
    {
      "epoch": 0.9044671560865601,
      "grad_norm": 0.0036236790474504232,
      "learning_rate": 1.9116165251187567e-06,
      "loss": 0.0899,
      "step": 18850
    },
    {
      "epoch": 0.9068662732114582,
      "grad_norm": 0.007977818138897419,
      "learning_rate": 1.8636341826207957e-06,
      "loss": 0.0769,
      "step": 18900
    },
    {
      "epoch": 0.9092653903363562,
      "grad_norm": 2.6251273155212402,
      "learning_rate": 1.8156518401228349e-06,
      "loss": 0.0919,
      "step": 18950
    },
    {
      "epoch": 0.9116645074612543,
      "grad_norm": 0.007461689878255129,
      "learning_rate": 1.7676694976248742e-06,
      "loss": 0.0832,
      "step": 19000
    },
    {
      "epoch": 0.9140636245861523,
      "grad_norm": 1.1279815435409546,
      "learning_rate": 1.7196871551269134e-06,
      "loss": 0.0845,
      "step": 19050
    },
    {
      "epoch": 0.9164627417110504,
      "grad_norm": 1.301863670349121,
      "learning_rate": 1.6717048126289526e-06,
      "loss": 0.0935,
      "step": 19100
    },
    {
      "epoch": 0.9188618588359484,
      "grad_norm": 1.419124960899353,
      "learning_rate": 1.623722470130992e-06,
      "loss": 0.1006,
      "step": 19150
    },
    {
      "epoch": 0.9212609759608464,
      "grad_norm": 1.1969574689865112,
      "learning_rate": 1.5757401276330311e-06,
      "loss": 0.0825,
      "step": 19200
    },
    {
      "epoch": 0.9236600930857445,
      "grad_norm": 1.1038504838943481,
      "learning_rate": 1.5277577851350703e-06,
      "loss": 0.0855,
      "step": 19250
    },
    {
      "epoch": 0.9260592102106425,
      "grad_norm": 6.889070510864258,
      "learning_rate": 1.4797754426371097e-06,
      "loss": 0.0828,
      "step": 19300
    },
    {
      "epoch": 0.9284583273355406,
      "grad_norm": 1.0055996179580688,
      "learning_rate": 1.4317931001391488e-06,
      "loss": 0.0913,
      "step": 19350
    },
    {
      "epoch": 0.9308574444604386,
      "grad_norm": 0.7994577288627625,
      "learning_rate": 1.3838107576411882e-06,
      "loss": 0.0838,
      "step": 19400
    },
    {
      "epoch": 0.9332565615853365,
      "grad_norm": 0.006939814891666174,
      "learning_rate": 1.3358284151432274e-06,
      "loss": 0.092,
      "step": 19450
    },
    {
      "epoch": 0.9356556787102346,
      "grad_norm": 1.6774377822875977,
      "learning_rate": 1.2878460726452665e-06,
      "loss": 0.1053,
      "step": 19500
    },
    {
      "epoch": 0.9380547958351326,
      "grad_norm": 0.83447265625,
      "learning_rate": 1.239863730147306e-06,
      "loss": 0.0958,
      "step": 19550
    },
    {
      "epoch": 0.9404539129600307,
      "grad_norm": 0.9083977341651917,
      "learning_rate": 1.191881387649345e-06,
      "loss": 0.0933,
      "step": 19600
    },
    {
      "epoch": 0.9428530300849287,
      "grad_norm": 1.7730251550674438,
      "learning_rate": 1.1438990451513845e-06,
      "loss": 0.0961,
      "step": 19650
    },
    {
      "epoch": 0.9452521472098268,
      "grad_norm": 1.3899970054626465,
      "learning_rate": 1.0959167026534236e-06,
      "loss": 0.1115,
      "step": 19700
    },
    {
      "epoch": 0.9476512643347248,
      "grad_norm": 0.8846701979637146,
      "learning_rate": 1.0479343601554628e-06,
      "loss": 0.0917,
      "step": 19750
    },
    {
      "epoch": 0.9500503814596228,
      "grad_norm": 0.9293479323387146,
      "learning_rate": 9.999520176575022e-07,
      "loss": 0.0807,
      "step": 19800
    },
    {
      "epoch": 0.9524494985845209,
      "grad_norm": 0.002227179007604718,
      "learning_rate": 9.519696751595415e-07,
      "loss": 0.0804,
      "step": 19850
    },
    {
      "epoch": 0.9548486157094189,
      "grad_norm": 1.7251149415969849,
      "learning_rate": 9.039873326615805e-07,
      "loss": 0.0906,
      "step": 19900
    },
    {
      "epoch": 0.957247732834317,
      "grad_norm": 0.0014225083868950605,
      "learning_rate": 8.560049901636198e-07,
      "loss": 0.0653,
      "step": 19950
    },
    {
      "epoch": 0.959646849959215,
      "grad_norm": 1.752328872680664,
      "learning_rate": 8.080226476656592e-07,
      "loss": 0.089,
      "step": 20000
    },
    {
      "epoch": 0.962045967084113,
      "grad_norm": 0.7628173828125,
      "learning_rate": 7.600403051676985e-07,
      "loss": 0.0899,
      "step": 20050
    },
    {
      "epoch": 0.9644450842090111,
      "grad_norm": 4.385225296020508,
      "learning_rate": 7.120579626697375e-07,
      "loss": 0.1026,
      "step": 20100
    },
    {
      "epoch": 0.9668442013339091,
      "grad_norm": 2.0131237506866455,
      "learning_rate": 6.640756201717768e-07,
      "loss": 0.0834,
      "step": 20150
    },
    {
      "epoch": 0.9692433184588072,
      "grad_norm": 1.4168728590011597,
      "learning_rate": 6.160932776738161e-07,
      "loss": 0.0905,
      "step": 20200
    },
    {
      "epoch": 0.9716424355837052,
      "grad_norm": 0.005152733530849218,
      "learning_rate": 5.681109351758553e-07,
      "loss": 0.0901,
      "step": 20250
    },
    {
      "epoch": 0.9740415527086033,
      "grad_norm": 1.2961757183074951,
      "learning_rate": 5.201285926778945e-07,
      "loss": 0.0949,
      "step": 20300
    },
    {
      "epoch": 0.9764406698335013,
      "grad_norm": 0.9119454026222229,
      "learning_rate": 4.7214625017993384e-07,
      "loss": 0.0879,
      "step": 20350
    },
    {
      "epoch": 0.9788397869583993,
      "grad_norm": 0.7228259444236755,
      "learning_rate": 4.2416390768197306e-07,
      "loss": 0.0845,
      "step": 20400
    },
    {
      "epoch": 0.9812389040832974,
      "grad_norm": 1.9741929769515991,
      "learning_rate": 3.7618156518401233e-07,
      "loss": 0.09,
      "step": 20450
    },
    {
      "epoch": 0.9836380212081954,
      "grad_norm": 0.0029252280946820974,
      "learning_rate": 3.2819922268605155e-07,
      "loss": 0.0956,
      "step": 20500
    },
    {
      "epoch": 0.9860371383330935,
      "grad_norm": 0.9487972855567932,
      "learning_rate": 2.8021688018809083e-07,
      "loss": 0.0832,
      "step": 20550
    },
    {
      "epoch": 0.9884362554579914,
      "grad_norm": 1.937406301498413,
      "learning_rate": 2.3223453769013005e-07,
      "loss": 0.077,
      "step": 20600
    },
    {
      "epoch": 0.9908353725828895,
      "grad_norm": 0.0024587023071944714,
      "learning_rate": 1.8425219519216932e-07,
      "loss": 0.0784,
      "step": 20650
    },
    {
      "epoch": 0.9932344897077875,
      "grad_norm": 5.350505828857422,
      "learning_rate": 1.3626985269420854e-07,
      "loss": 0.0935,
      "step": 20700
    },
    {
      "epoch": 0.9956336068326855,
      "grad_norm": 1.1682136058807373,
      "learning_rate": 8.828751019624779e-08,
      "loss": 0.0843,
      "step": 20750
    },
    {
      "epoch": 0.9980327239575836,
      "grad_norm": 0.002947924192994833,
      "learning_rate": 4.030516769828703e-08,
      "loss": 0.0995,
      "step": 20800
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9404764760922243,
      "eval_f1": 0.9391692178874083,
      "eval_loss": 0.08926980197429657,
      "eval_precision": 0.9410656438457462,
      "eval_recall": 0.9404764760922243,
      "eval_runtime": 287.0347,
      "eval_samples_per_second": 290.425,
      "eval_steps_per_second": 18.155,
      "step": 20841
    }
  ],
  "logging_steps": 50,
  "max_steps": 20841,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1043501894434304e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
